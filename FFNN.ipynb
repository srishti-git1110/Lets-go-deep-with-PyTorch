{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FFNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMrHRUAYEA3luxvoLw8fi/0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srishti-git1110/Simple_NN_in_PyTorch/blob/main/FFNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is just to get a hands on demo of pytorch for ones who know what neural networks are & their working in theory, and want to implement their theoretical knowledge in pytorch.\n",
        "You can run this nb on a gpu as well as cpu.\n",
        "\n",
        "We construct a very short network here working on MNIST data."
      ],
      "metadata": {
        "id": "rbtBL5tu6DnG"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-ZOBVgEThS7"
      },
      "source": [
        "import torch.nn as nn #ffnn, cnn, rnn etc\n",
        "import torch.optim as optim #optimisers like sgd etc\n",
        "import torch.nn.functional as f #activ funcs\n",
        "from torch.utils.data import DataLoader #minibatch train test etc\n",
        "import torchvision.datasets as datasets #std datasets\n",
        "import torchvision.transforms as transforms #transformations to perform on dataset\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "x = torch.rand(size=(64,10))\n",
        "_, predictions = x.max(1)\n",
        "print(x.max(1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-x5ozzEUylzL",
        "outputId": "56674aa7-b37d-48cf-ee1e-857bce4b55d3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.return_types.max(\n",
            "values=tensor([0.8831, 0.9590, 0.7447, 0.8181, 0.9913, 0.9424, 0.8740, 0.6849, 0.9429,\n",
            "        0.9806, 0.8797, 0.8810, 0.9785, 0.9850, 0.8550, 0.9733, 0.9678, 0.7914,\n",
            "        0.7959, 0.8727, 0.9407, 0.9979, 0.6810, 0.8131, 0.9454, 0.9641, 0.7145,\n",
            "        0.8946, 0.9875, 0.9655, 0.8828, 0.9104, 0.9815, 0.8680, 0.9967, 0.9163,\n",
            "        0.8877, 0.9889, 0.9253, 0.8084, 0.7278, 0.9804, 0.9271, 0.8693, 0.9391,\n",
            "        0.8525, 0.6139, 0.9333, 0.9073, 0.8948, 0.8275, 0.8844, 0.9992, 0.9056,\n",
            "        0.8856, 0.7761, 0.8785, 0.8311, 0.9673, 0.7846, 0.9639, 0.9899, 0.9435,\n",
            "        0.8852]),\n",
            "indices=tensor([2, 9, 4, 9, 3, 8, 4, 2, 2, 4, 0, 8, 9, 6, 2, 6, 3, 4, 7, 1, 4, 6, 9, 2,\n",
            "        6, 1, 0, 9, 4, 4, 9, 9, 3, 2, 1, 5, 3, 3, 6, 9, 3, 0, 7, 4, 9, 4, 0, 7,\n",
            "        8, 6, 4, 8, 7, 3, 8, 1, 9, 1, 2, 4, 2, 4, 9, 3]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class NN(nn.Module):\n",
        "  def __init__(self, input_size, num_classes):\n",
        "    super(NN, self).__init__()\n",
        "    self.fc1 = nn.Linear(in_features=input_size, out_features=50)\n",
        "    self.fc2 = nn.Linear(in_features=50, out_features=num_classes)\n",
        "\n",
        "  def forward(self, x): #x is the data examples*features\n",
        "    x = f.relu(self.fc1(x)) \n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "input_size = 784\n",
        "num_classes = 10\n",
        "learning_rate = .001\n",
        "batch_size = 64\n",
        "epochs = 1\n",
        "\n",
        "#load data\n",
        "train_set = datasets.MNIST(root='dataset/', train=True, transform=transforms.ToTensor(), download=True)\n",
        "train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_set = datasets.MNIST(root='dataset/', train=False, transform=transforms.ToTensor(), download=True)\n",
        "test_loader = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "#initialize\n",
        "model = NN(input_size, num_classes).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "#train\n",
        "for epoch in range(epochs):\n",
        "  for batch_num, (data, targets) in enumerate(train_loader):\n",
        "    data = data.to(device=device)\n",
        "    targets = targets.to(device=device)\n",
        "    data = data.reshape(data.shape[0], -1)\n",
        "    #forward\n",
        "    scores = model(data)\n",
        "    loss = criterion(scores, targets)\n",
        "\n",
        "    #backward\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "def check_accuracy(loader, model):\n",
        "  if loader.dataset.train:\n",
        "    print(\"checking accuracy on train data\")\n",
        "  else:\n",
        "    print(\"checking accuracy on test data\")\n",
        "  num_correct = 0\n",
        "  num_samples = 0\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for x, y in loader:\n",
        "      x = x.to(device=device)\n",
        "      y = y.to(device=device)\n",
        "      x = x.reshape(x.shape[0], -1)\n",
        "\n",
        "      scores = model(x) #64*10\n",
        "      _, predictions = scores.max(1) #probs, indices\n",
        "      num_correct += (predictions == y).sum()\n",
        "      num_samples += predictions.size(0)\n",
        "    print(f'Accuracy {float(num_correct)/float(num_samples)*100:.2f}')\n",
        "  model.train()\n",
        "  \n",
        "\n",
        "check_accuracy(train_loader, model)\n",
        "check_accuracy(test_loader, model)"
      ],
      "metadata": {
        "id": "dbrevt7aI4tQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0101d4b-b5ac-4b56-919d-02440ebcf80b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checking accuracy on train data\n",
            "Accuracy 93.38\n",
            "checking accuracy on test data\n",
            "Accuracy 93.36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nzB_KexcI48e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OeKDoazjI4_w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}